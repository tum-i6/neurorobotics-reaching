{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7dd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys                       \n",
    "import numpy as np                \n",
    "\n",
    "# env checker\n",
    "try:\n",
    "    from stable_baselines3.common import env_checker\n",
    "except ModuleNotFoundError: \n",
    "    !pip install stable-baselines3==1.2.0\n",
    "    from stable_baselines3.common import env_checker\n",
    "\n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "# stable baselines3 -> SAC\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.sac import MlpPolicy\n",
    "\n",
    "from sac_torch import Agent\n",
    "\n",
    "# Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('tensorboard_log/',comment=\"-SAC_HER_buff20000\")\n",
    "\n",
    "# grpc communication\n",
    "sys.path.insert(1, '/tum_nrp/grpc/python/communication')\n",
    "import experiment_api_wrapper as eaw\n",
    "\n",
    "sys.path.insert(1, '/tum_nrp/rlmodel/sb3')\n",
    "from env import SimEnv\n",
    "from train_helpers import evaluate, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88860ea",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e42ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"img_pi_data\": 0,                 # 1 laod image data from .pi file, 0 do not load image data\n",
    "    \"train_loader\": None,             # Specifies the loader for the training data\n",
    "    \"test_loader\": None,              # Specifies the loader for the test data\n",
    "    \"VERBOSE\": 1,                     \n",
    "    \"SETTING\": 'reduced4',            # 'reduced', 'reduced2', 'reduced3', 'reduced3+', 'reduced4', 'reduced4+'\n",
    "    \"OBJ_SPACE_LOW\": np.array([-0.92, -0.51, 0.58, -0.44, -0.48, 0, -np.pi/2, -np.pi/2, -0.001, -np.pi/2, -0.001, -np.pi]), # observation-space (ee-pos, cyl-pos, joints)\n",
    "    \"OBJ_SPACE_HIGH\": np.array([0.92, 1.32, 2.07, 0.48, 0.44, 1.12, np.pi/2, 0.001, np.pi, np.pi/2, np.pi, np.pi]),\n",
    "    \"SPACE_NORM\": 1,                  #  1 -> yes, 0 -> no (normalize the action and observation space)\n",
    "    \"CYLINDER\": 'no',                 # 'no', fix', 'semi_random', 'semi_random_sides', 'half_table', '3/4-table', '7/8-table', 'whole_table'\n",
    "    \"BUFFER_SIZE\": 2000,\n",
    "    \"THRESHOLD\": 0.25,                # initial treshold\n",
    "    \"THRESHOLD_SCHEDULING\": 1,        # 1-> yes, 0-> no\n",
    "    \"MIN_THRESHOLD\": 0.10,\n",
    "    \"REWARD_TYPE\": 'dense',           # 'sparse', 'dense', 'extra_dense'\n",
    "    \"LEARNING_STARTS\": 15,            # number of random movements before learning starts,#\n",
    "    \"TOGGLE_REWARD\": 0,\n",
    "    \"STEPS\": 4000,                    # number of steps while training (=num_episodes when MAX_EPISODE_LEGTH is 1)\n",
    "    \"MAX_EPISODE_LENGTH\": 1,          # 'None' (no limit) or value \n",
    "    \"EXPLORATION\": 25,                # just let it on 1 and ignore it\n",
    "    \"WRITER\": writer,\n",
    "    \"USE_HER\": 0,                     # 1-> yes, 0-> no\n",
    "    \"ENTROPY_COEFFICIENT\": 0.007,     # 'auto' or value between 0 and 1 // 0.007 turned out to work well\n",
    "    \"GLOBAL_STEPPER\": 0, \n",
    "    \"EVALUATION_STEPS\": 30,           # number of evaluation steps per investigates treshold (x4)\n",
    "    \"EVALS\": [0.30, 0.25, 0.2, 0.15], # here, the list MUST contain always 4 tresholds for evaluation\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"ACTION_NOISE\": None,\n",
    "    \"RANDOM_EXPLORATION\": 0.0,\n",
    "    \"LR\": 3e-4,\n",
    "    \"TB_LOGGER\": None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847973b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d110095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1631786010.327216533\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3008,\"referenced_errors\":[{\"created\":\"@1631786010.327212322\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":397,\"grpc_status\":14}]}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9bb8dfa37d0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# test if simulation can be reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mserver_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mserver_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Simulation is available, id: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tum_nrp/grpc/python/communication/communication_client.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# send test request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         response = self.stub.Test(communication_pb2.RequestEmpty(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mclient_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             ))\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     def with_call(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses\"\n\tdebug_error_string = \"{\"created\":\"@1631786010.327216533\",\"description\":\"Failed to pick subchannel\",\"file\":\"src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3008,\"referenced_errors\":[{\"created\":\"@1631786010.327212322\",\"description\":\"failed to connect to all addresses\",\"file\":\"src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":397,\"grpc_status\":14}]}\"\n>"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # create a experiment (connection)\n",
    "    exp = eaw.ExperimentWrapper()\n",
    "\n",
    "    # test if simulation can be reached\n",
    "    server_id = exp.client.test()\n",
    "    if server_id:\n",
    "        print(\"Simulation is available, id: \", server_id)\n",
    "    else:\n",
    "        print(\"Simulation NOT available\")\n",
    "        \n",
    "        \n",
    "    # create an environment (choice depends on usage of HER)\n",
    "    env = SimEnv(exp, params, writer)\n",
    "        \n",
    "    # check env\n",
    "    env_checker.check_env(env)\n",
    "\n",
    "\n",
    "    # setup custome sac agent\n",
    "    agent = Agent(alpha=0.0003, beta=params[\"LR\"], input_dims=env.observation_space.shape, env=env, \n",
    "                  gamma=0.99, n_actions=env.action_space.shape[0], max_size=params[\"BUFFER_SIZE\"], \n",
    "                  tau=0.005, layer1_size=256, layer2_size=256, batch_size=params[\"BATCH_SIZE\"], \n",
    "                  reward_scale=params[\"EXPLORATION\"])\n",
    "\n",
    "\n",
    "    best_score = 0\n",
    "    score_history = []\n",
    "    load_checkpoint = False\n",
    "\n",
    "    avg_score = 0\n",
    "    \n",
    "    # counter used to evaluate the agent every Nth epoch\n",
    "    i = 0\n",
    "    \n",
    "    # run as long as the average score is less then 0.9 and for at least 100 epochs\n",
    "    while avg_score < 0.90 or i < 100: # if i < param[\"step\"]\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "\n",
    "        # catch error that occurs very rarely in the step function and give it a second chance\n",
    "        while not done:\n",
    "            # choose an action\n",
    "            action = agent.choose_action(observation)\n",
    "            # execute the chosen action\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            # save the observation, reward, etc. in the replay buffer\n",
    "            agent.remember(observation, action, reward, observation_, done)\n",
    "            \n",
    "            if not load_checkpoint:\n",
    "                # start the training process\n",
    "                agent.learn()\n",
    "            \n",
    "            # update the observation \n",
    "            observation = observation_\n",
    "         \n",
    "        # track the score and caculate the average score over the last 100 epochs\n",
    "        score_history.append(score)\n",
    "        avg_score = np.mean(score_history[-100:])\n",
    "        \n",
    "        # save a checkpoint if the current average score is better then all previous scores\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            if not load_checkpoint:\n",
    "                print('SAVING MODEL: episode ', i, 'score %.1f' % score, 'avg_score %.1f' % avg_score)\n",
    "                agent.save_models()\n",
    "                \n",
    "        # evaluate the model ever 1000th epoch        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            # disable plotting while evaluation because of some issues with inconsistent lengths\n",
    "            print(\"start evaluation\")\n",
    "            env.set_eval(ev=True)\n",
    "            try:\n",
    "                evaluate(agent, env, params)\n",
    "            except:\n",
    "                print(\"error while plotting\")\n",
    "            env.set_eval(ev=False)\n",
    "            print(\"stop evaluation\")\n",
    "\n",
    "        print('episode ', i, 'score %.1f' % score, 'avg_score %.1f' % avg_score)\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4b3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
