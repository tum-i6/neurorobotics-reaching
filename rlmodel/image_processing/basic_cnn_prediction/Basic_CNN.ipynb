{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, using basic CNN to process simple images is sufficient to retrieve a good result. However, because the data we are dealing with are vastly invariant, i.e., only the small cylinder's position changes while the rest of the image remains the same, it is almost impossible for the model to learn any features from the data input. This is also verified by our effort of Autoencoder. \n",
    "\n",
    "Therefore, we use transfer learning to avoid this issue. The CNN layers are first trained on [cifar-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). Then, the model is trained on actual dataset. \n",
    "\n",
    "Author: [Xiyan Su](mailto:tim.su@tum.de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from src.network import Model, PretrainedModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = \"./runs\"\n",
    "%tensorboard --logdir {logs_base_dir} --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining hyperparameters\n",
    "params = {\n",
    "    \"hidden_channel\": 20, #Number of hidden channels in CNN layer\n",
    "    \"hidden_layer\": 100,  #Number of hidden layers in FC layer\n",
    "    \"lr\": 1e-4,           #Initial learning rate\n",
    "    \"batch_size\": 8       #Batch size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading cifer-10 dataset for pretraining CNN layers\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifer_training_set = torchvision.datasets.CIFAR10(root=\"../data\",\n",
    "                                                  train=True,\n",
    "                                                  download = True, \n",
    "                                                  transform=transform\n",
    "                                                 )\n",
    "cifer_trainloader = torch.utils.data.DataLoader(cifer_training_set, batch_size=params[\"batch_size\"],\n",
    "                                          shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "cifer_test_set = torchvision.datasets.CIFAR10(root='../data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "cifer_testloader = torch.utils.data.DataLoader(cifer_test_set, batch_size=params[\"batch_size\"],\n",
    "                                         shuffle=False, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the model instance\n",
    "# model = Model(params)\n",
    "model = PretrainedModel(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Tensorboard for pretraining\n",
    "writer = SummaryWriter('logs/pretrained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pretrained model if already trained\n",
    "# pretrained_params = torch.load('./saved_models/pretrained_model_params', map_location=torch.device(device))\n",
    "# model.load_state_dict(pretrained_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-training the model using cifar-10 dataset\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for idx, data in enumerate(cifer_trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        step_loss = loss(outputs, labels)\n",
    "        epoch_loss += step_loss\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "    writer.add_scalar('Pretrained_training_loss/Epoch', epoch_loss, epoch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for idx, data in enumerate(cifer_testloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            step_loss = loss(outputs, labels)\n",
    "            val_loss += step_loss\n",
    "        writer.add_scalar('Pretrained_validation_loss/Epoch', val_loss, epoch)\n",
    "    \n",
    "    if epoch==1:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "    elif val_loss<best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"./saved_models/new/pretrained_model_params\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Early stop while overfitting\n",
    "    if epoch>(best_epoch+5):\n",
    "        print(\"Reached post-best limit, Training ended.\")\n",
    "        print(f'Best loss is {best_loss}')\n",
    "        break\n",
    "    print(f'[Epoch {epoch:3d}, training loss: {epoch_loss:.10f}, validation loss: {val_loss:.10f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matching state dict\n",
    "pretrained_model = model\n",
    "pretrained_model_params = torch.load(\"./saved_models/pretrained_model_params\", map_location=torch.device(device))\n",
    "model = Model(params)\n",
    "pretrained_model_params[\"model.7.weight\"] = model.state_dict()[\"model.7.weight\"]\n",
    "pretrained_model_params[\"model.7.bias\"] = model.state_dict()[\"model.7.bias\"]\n",
    "pretrained_model_params[\"model.9.weight\"] = model.state_dict()[\"model.9.weight\"]\n",
    "pretrained_model_params[\"model.9.bias\"] = model.state_dict()[\"model.9.bias\"]\n",
    "model.load_state_dict(pretrained_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset from .pt files and dividing into training and validation sets\n",
    "training_dataset_normalized = torch.load('../data/training_data.pt')[0:1750]\n",
    "val_dataset_normalized = torch.load('../data/training_data.pt')[1750:2000]\n",
    "\n",
    "#Normalizing the datasets manually\n",
    "for idx, [img, _] in enumerate(training_dataset_normalized):\n",
    "    training_dataset_normalized[idx][0] = (F.normalize(img.type(torch.float), dim=2) - 0.5) * 2\n",
    "for idx, [img, _] in enumerate(val_dataset_normalized):\n",
    "    val_dataset_normalized[idx][0] = (F.normalize(img.type(torch.float), dim=2) - 0.5) * 2\n",
    "\n",
    "#Load data into pytorch DataLoader\n",
    "training_dataloader = DataLoader(training_dataset_normalized, batch_size=params[\"batch_size\"], drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset_normalized, batch_size=params[\"batch_size\"], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Tensorboard for acutal training\n",
    "writer = SummaryWriter('logs/cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#Loading weights from the saved model\n",
    "# model.load_state_dict(torch.load(\"saved_models/cnn_model\"), map_location=torch.device(device))\n",
    "model.to(device)\n",
    "\n",
    "#Defining the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "for epoch in range(1, 3000):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_idx, data in enumerate(training_dataloader):\n",
    "        img = data[0].reshape((8, -1 ,120, 120)).type(torch.cuda.FloatTensor)\n",
    "        pos = 10*torch.stack(data[1][0:2], dim=1).type(torch.cuda.FloatTensor)\n",
    "        img, pos = img.to(device), pos.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        output = output.to(device)\n",
    "        step_loss = loss(pos, output)\n",
    "        epoch_loss += step_loss.item()\n",
    "        step_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for batch_idx, data in enumerate(val_dataloader):\n",
    "            img = data[0].reshape((8, -1 ,120, 120)).type(torch.cuda.FloatTensor)\n",
    "            pos = 10*torch.stack(data[1][0:2], dim=1).type(torch.cuda.FloatTensor)\n",
    "            img, pos = img.to(device), pos.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            output = output.to(device)\n",
    "            step_loss = loss(pos, output)\n",
    "            val_loss += step_loss.item()\n",
    "\n",
    "        writer.add_scalar(\"Epoch_validation_loss/train\", val_loss, epoch)\n",
    "        \n",
    "    #Save the best model\n",
    "    if epoch==1:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "    elif val_loss<best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"saved_models/new/cnn_model\")\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Early stop while overfitting\n",
    "    if epoch>(best_epoch+20):\n",
    "        print(\"Reached post-best limit, Training ended.\")\n",
    "        print(f'Best loss is {best_loss}')\n",
    "        break\n",
    "    \n",
    "    print(f'[Epoch {epoch:4d}, training loss: {epoch_loss/7:.10f}, validation loss: {val_loss:.10f}]')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if trained, re-load the model here.\n",
    "model = Model(params)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/cnn_model\", map_location=torch.device(device)))\n",
    "\n",
    "#datasets used for visualization\n",
    "training_dataset = torch.load('../data/training_data.pt', map_location=torch.device(device))[0:1750]\n",
    "val_dataset = torch.load('../data/training_data.pt', map_location=torch.device(device))[1750:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions to retrieve pixel-wise coordinates\n",
    "def x_pixel(cylinder_y):\n",
    "    return ((0.48 - cylinder_y) * 120 / (0.48+0.48))\n",
    "\n",
    "def y_pixel(cylinder_x):\n",
    "    return ((0.48 - cylinder_x) * 120 / (0.48+0.48))\n",
    "\n",
    "#Visualizing the results\n",
    "def plot_cylinder(model):\n",
    "    imgs = []\n",
    "    poses = []\n",
    "    outputs = []\n",
    "    fig = plt.figure(figsize=(80, 40))\n",
    "    for idx, data in enumerate(val_dataset):\n",
    "        if idx==8:\n",
    "            break\n",
    "        elif idx>=0:\n",
    "            img = data[0]\n",
    "            img_np = img.numpy()\n",
    "            img = (F.normalize(img.type(torch.float), dim=2) - 0.5) * 2\n",
    "            img.to(device)\n",
    "            pos = data[1]\n",
    "            pixel = (int(np.around(x_pixel(pos[1]))), int(np.around(y_pixel(pos[0]))))\n",
    "            output = model(img.reshape((1, -1 ,120, 120)).type(torch.float)).cpu() / 10\n",
    "            output_np = output.detach().numpy()\n",
    "            pixel = (int(np.around(x_pixel(output_np[0][1]))), int(np.around(y_pixel(output_np[0][0]))))\n",
    "            fig.add_subplot(2, 4, idx+1)\n",
    "            plt.imshow(img_np)\n",
    "            plt.scatter(pixel[0], pixel[1], linewidths=10, s=4000, facecolors='none', edgecolors='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cylinder(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
